{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T01:18:18.388549Z",
     "iopub.status.busy": "2023-11-22T01:18:18.388043Z",
     "iopub.status.idle": "2023-11-22T01:18:21.239778Z",
     "shell.execute_reply": "2023-11-22T01:18:21.238890Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alsdyd98/anaconda3/envs/instblip/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'\n",
    "device = \"cuda:5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T01:18:21.245335Z",
     "iopub.status.busy": "2023-11-22T01:18:21.245010Z",
     "iopub.status.idle": "2023-11-22T01:18:21.248879Z",
     "shell.execute_reply": "2023-11-22T01:18:21.248304Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/tree/main/projects/instructblip#prepare-vicuna-weights\n",
    "#!pip3 install \"fschat[model_worker,webui]\"\n",
    "#!python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T01:18:21.253502Z",
     "iopub.status.busy": "2023-11-22T01:18:21.253270Z",
     "iopub.status.idle": "2023-11-22T01:19:21.795541Z",
     "shell.execute_reply": "2023-11-22T01:19:21.794806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 14.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n",
    "model = InstructBlipForConditionalGeneration.from_pretrained(\"Salesforce/instructblip-vicuna-7b\", device_map = device, load_in_4bit=True, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T01:19:21.801105Z",
     "iopub.status.busy": "2023-11-22T01:19:21.800868Z",
     "iopub.status.idle": "2023-11-22T01:19:21.807810Z",
     "shell.execute_reply": "2023-11-22T01:19:21.807180Z"
    }
   },
   "outputs": [],
   "source": [
    "class AnswerGenerator:\n",
    "    def __init__(self, model, preprocessor, device='cuda'):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load(self, image, prompt):\n",
    "        if type(image) == str:\n",
    "            raw_image = Image.open(image).convert(\"RGB\")\n",
    "        else:\n",
    "            raw_image = image\n",
    "        # image_emb = self.preprocessor[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "        inputs = processor(images=raw_image, text=prompt, return_tensors=\"pt\").to(device=device, dtype=torch.float16)\n",
    "        return inputs\n",
    "\n",
    "    def inference(self, image, prompt):\n",
    "        inputs = self._load(image, prompt)\n",
    "        # qaSet = {\"image\": img_emb, \"prompt\": prompt}\n",
    "        outputs = self.model.generate(**inputs,         \n",
    "        num_beams=5,\n",
    "        max_new_tokens=1024,\n",
    "        min_length=1,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.5,\n",
    "        length_penalty=1.0,\n",
    "        temperature=1,)\n",
    "        # print(processor.batch_decode(outputs, skip_special_tokens=True))\n",
    "        generated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T01:19:21.812866Z",
     "iopub.status.busy": "2023-11-22T01:19:21.812630Z",
     "iopub.status.idle": "2023-11-22T03:08:36.224574Z",
     "shell.execute_reply": "2023-11-22T03:08:36.223727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/70 [00:00<?, ?it/s]/home/alsdyd98/anaconda3/envs/instblip/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n",
      "100%|██████████| 70/70 [1:49:14<00:00, 93.63s/it]\n"
     ]
    }
   ],
   "source": [
    "llm = AnswerGenerator(model, processor, device)\n",
    "base_dir = \".\"\n",
    "# key: imageFile_name, value: [{key(Q_i):value(question description)}]\n",
    "with open(f'{base_dir}/question_data_updated.json', 'r') as f:\n",
    "    question_dict = json.load(f)\n",
    "\n",
    "answer_dict = {}\n",
    "print(len(list(question_dict.keys())))\n",
    "for fileName in tqdm(list(question_dict.keys())[160:]):\n",
    "    answer_dict[fileName] = {}\n",
    "    for q in question_dict[fileName]:\n",
    "        # img_dir = f'{base_dir}/images/whoops_images/{fileName}.png'\n",
    "        img_dir = f'{base_dir}/images/black_image.jpg'\n",
    "        ans = llm.inference(img_dir, question_dict[fileName][q])\n",
    "        ansKey = q\n",
    "        answer_dict[fileName][ansKey] = ans\n",
    "    with open(f'{base_dir}/answer_set_true_black_3.json', 'w') as outfile:\n",
    "        json.dump(answer_dict, outfile)\n",
    "\n",
    "with open(f'{base_dir}/answer_set_true_black_3.json', 'w') as outfile:\n",
    "    json.dump(answer_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instblip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
